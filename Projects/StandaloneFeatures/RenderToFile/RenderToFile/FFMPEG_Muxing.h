#pragma once
/*
 * Copyright (c) 2003 Fabrice Bellard
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 */

#include <string>
#include <vector>
#include <algorithm>

//#pragma warning(disable 4996)
#define __STDC_CONSTANT_MACROS
extern "C"
{
#include <libavutil/avassert.h>
#include <libavutil/channel_layout.h>
#include <libavutil/opt.h>
#include <libavutil/mathematics.h>
#include <libavutil/timestamp.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <libswresample/swresample.h>
}

struct MuxerSettings /* Building the needed configuration for muxing. */
{
	std::string m_fileName = "default.mp4";
	double m_streamDuration = 10.0;

	/* Video */
	int m_framerate = 60; /* 25 images/s */
	AVPixelFormat m_pixelFormat = AV_PIX_FMT_YUV420P; /* default pix_fmt is AV_PIX_FMT_YUV420P*/
	int m_frameWidth = 800;
	int m_frameHeight = 600;
	int m_videoBitRate = 40000000;

	/* Audio */
	int m_audioBitRate = 320000;
	int m_audioDefaultSampleRate = 48000;
	uint64_t m_audioChannels = AV_CH_LAYOUT_STEREO;

};

// a wrapper around a single output AVStream
typedef struct OutputStream {

	/* B.G: Comparator checks positions of streams against each other in their own timebases. */
	bool operator<(const OutputStream & other)
	{
		return (av_compare_ts(next_pts, enc->time_base, other.next_pts, other.enc->time_base) >= 0);
	}
	/* B.G: Compare the timecodes of each stream to find which stream to encode the next frame from. */
	static std::vector<OutputStream>::iterator & nextStream(std::vector<OutputStream> & streams)
	{
		return std::max_element(streams.begin(), streams.end());
	}
	/* B.G : TODO: Who is responsible for the time at which streams are finished?
				I suspect that all frames of each stream need to be written up to a single end-time, to make videos look smooth.
				Leave it this way for now.
	*/
	static bool streamsUnfinshed(std::vector<OutputStream>& streams, double endTime)
	{
		for (auto i = streams.begin(); i != streams.end(); ++i)
		{
			if (av_compare_ts(i->next_pts, i->enc->time_base, (int64_t)endTime, av_make_q(1, 1)) < 0)
				return true;
		}
		return false;
	}



	AVStream* st; /* ALLOCATION: Allocated independently, but owned by an AVFormatContext (I think)
								Not explicitly de-allocated. */
	AVCodecContext* enc;/* ALLOCATION: Allocated independently  */

	/* pts of the next frame that will be generated */
	int64_t next_pts;
	int samples_count;

	AVFrame* frame; /* ALLOCATION: Allocated independently  */
	AVFrame* tmp_frame; /* ALLOCATION: Allocated independently  */

	float t, tincr, tincr2;

	struct SwsContext* sws_ctx; /* ALLOCATION: Allocated independently:
								Only for video streams, and
								only when the pixel format generated by the stream is
								different to the pixel format set up for muxing. */

	struct SwrContext* swr_ctx; /* ALLOCATION: Allocated independently:
								Only for audio streams */


	/* Bill: New fields*/
	AVCodec* p_codec = nullptr;
	bool m_initialised = false; // B.G: Replacement for have_audio/have_video
	bool m_finished = false; // B.G: (inverted) replacement for encode_audio/encode_video

	
	//enum StreamAllocation
	//{
	//	None = 0x00,
	//	//Stream = 0x01,
	//	CodecContext = 0x01,
	//	Frame_Main = 0x02,
	//	Frame_Temp = 0x04,
	//	SWS_Context = 0x08,
	//	SWR_Context = 0x10,
	//} m_allocation;

	void deallocate();
} OutputStream;

class FFMPEG_Muxer
{
public:
	FFMPEG_Muxer()
		:
		m_initialised{false}
	{
	}

	/* true on success */
	bool initialise(MuxerSettings settings);
	void run();
	void deinitialise();

	void reportError(std::string description, int errorNum = 0);
private:
	void log_packet(const AVFormatContext* fmt_ctx, const AVPacket* pkt);

	int write_frame(AVFormatContext* fmt_ctx, const AVRational* time_base, AVStream* st, AVPacket* pkt);

	bool add_stream(OutputStream* ost, AVFormatContext* oc, AVCodec** codec, enum AVCodecID codec_id);

	AVFrame* alloc_audio_frame(enum AVSampleFormat sample_fmt, uint64_t channel_layout, int sample_rate, int nb_samples);

	void open_audio(AVFormatContext* oc, AVCodec* codec, OutputStream* ost, AVDictionary* opt_arg);

	/* Prepare a 16 bit dummy audio frame of 'frame_size' samples and
	 * 'nb_channels' channels. */
	/* B.G: Generates array of data using the output stream's properties and index:
		Options:
			-> Make an output stream hold this method.
				-> ie. move it out of the muxer and into a StreamGenerator.
			-> Unify this with get_video_frame() by:
		IMPROVEMENTS:
			-> 
	*/
	AVFrame * get_audio_frame(OutputStream* ost);

	int write_audio_frame(AVFormatContext* oc, OutputStream* ost);

	AVFrame* alloc_picture(enum AVPixelFormat pix_fmt, int width, int height);

	void open_video(AVFormatContext* oc, AVCodec* codec, OutputStream* ost, AVDictionary* opt_arg);

	void fill_yuv_image(AVFrame* pict, int frame_index, int width, int height);

	/* B.G: This makes the video frame. */
	AVFrame* get_video_frame(OutputStream* ost);

	int write_video_frame(AVFormatContext* oc, OutputStream* ost);

	void close_stream(AVFormatContext* oc, OutputStream* ost);
private:
	MuxerSettings m_settings;
	bool m_initialised;

	OutputStream video_st = { 0 }, audio_st = { 0 };
	const char* filename{ nullptr };
	AVOutputFormat* fmt{ nullptr }; /* Owned by the AVFormatContext, oc. Holds output format information. */

	/* B.G:
		-> This is the Output Media Context
		-> Takes the filename, allocated with avformat_alloc_output_context2().
	*/
	AVFormatContext* oc{ nullptr };
	AVCodec* audio_codec{ nullptr }, * video_codec{ nullptr };
	int ret{ 0 };
	AVDictionary* opt{ nullptr };

	/* B.G: Vector of streams. */
	std::vector<OutputStream> m_streams;



	/* Keep track of what was allocated, so we can free what we need to,
		to minimise fatal exits. */
	enum AllocationStage
	{
		None = 0x00,
		Output_FormatContext = 0x01,
		OutputStream_Stream = 0x02,
		OutputStream_CodecContext = 0x04,

		OutputStream_AudioFrame = 0x080,

	} m_allocationStage;
	bool deallocate();
};